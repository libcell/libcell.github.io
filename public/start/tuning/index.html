<!DOCTYPE html>
<html>
<head>
<!DOCTYPE html>
<html lang="en-us">



<link rel="stylesheet" href="/css/fonts.css">
<link rel="stylesheet" href="/css/main-site.css">
<link rel="stylesheet" href="/css/fa5-all.css">
<style type="text/css">
    body {
	background-color: #ffffff;
	color: #404040
}

/* Links */

a {
  color: #CA225E;
}

a:hover {
  color: #cc3168;
}

/* Landing page content bands */

#homeContent .band.first {
  background-color: #ffffff
}

#homeContent .band.second {
  background-color: #fcfcfc
}

#homeContent .band.third {
  background-color: #ffffff
}

/* Top navigation bar menu */

#rStudioHeader {
  background-color: #ffffff;
  color: black;
}

#rStudioHeader .productName {
  color: #CA225E
}

#rStudioHeader .productName:hover {
  color: #00000075
}

#rStudioHeader #menu .menuItem.a {
  background-color: #75aadb;
  color: black;
}

#rStudioHeader #menu .menuItem:hover {
  background-color: white;
  color: #CA225E;
}

#rStudioHeader #menu .menuItem.current {
  background-color: #fcfcfc;
  color: #CA225E;
  text-decoration: none;
}

/* Footer */

#rStudioFooter.band {
  background-color: #CA225E40;
}

#rStudioFooter .bandContent #copyright {
  color: #CA225E;
}

/* Tables */

table tbody tr:nth-child(even){
  background-color: #fcfcfc;
}

table tbody tr:nth-child(odd){
  background-color: #1a162d10;
}

.latest {
  border-top: .5em solid <no value>;
}
</style>

  <link rel="stylesheet" href="/css/tm.css">




<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<meta name="apple-mobile-web-app-capable" content="yes" />

<meta name="og:image" content="https://www.tidymodels.org/images/feature_summary_large_image.jpg" >

  <meta property="twitter:card" content="summary_large_image">

<meta name="twitter:image" content="https://www.tidymodels.org/images/feature_summary_large_image.jpg" ><meta name="generator" content="Hugo 0.96.0" />

<meta property="og:type" content="website"><title>Get Started - Tune model parameters</title>
    <meta property="og:title" content="Get Started - Tune model parameters">
    
    
    
    
    <meta property="description" content="Estimate the best values for hyperparameters that cannot be learned directly during model training.
">
    <meta property="og:description" content="Estimate the best values for hyperparameters that cannot be learned directly during model training.
">



<link rel="apple-touch-icon" sizes="180x180" href="/images/favicons/apple-touch-icon.png" />
<link rel="icon" type="image/png" sizes="32x32" href="/images/favicons/favicon-32x32.png" />
<link rel="icon" type="image/png" sizes="16x16" href="/images/favicons/favicon-16x16.png" />
<link rel="manifest" href="/images/favicons/site.webmanifest" />
<link rel="mask-icon" href="/images/favicons/safari-pinned-tab.svg" />
<link rel="shortcut icon" href="/images/favicons/favicon.ico" />
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" href="/images/favicons/browserconfig.xml" >



<script type="text/javascript" src="/js/jquery-3.5.1.min.js"></script>
<script type="text/javascript" src="/js/site.js"></script>


  <script type="text/javascript" src="/js/tm.js"></script>


<link rel="icon" href="/images/favicon.ico" />


<script defer data-domain="tidymodels.org,all.tidymodels.org" src="https://plausible.io/js/plausible.js"></script>


<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script>


<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>



  <body>
    <div id="appTidyverseSite" class="shrinkHeader alwaysShrinkHeader">
      <div id="main">
        
        <div id="rStudioHeader">
          <div class="band">
            <div class="innards bandContent">
              <div>
                <a class="productName" href="/">Tidymodels</a>
                
              </div>
              <div id="menu">
  <div id="menuToggler"></div>
  <div id="menuItems" class="">
    
    
      
      
      
    <a class="menuItem " href="/packages/">Packages</a>
    
      
      
      
    <a class="menuItem current" href="/start/">Get Started</a>
    
      
      
      
    <a class="menuItem " href="/learn/">Learn</a>
    
      
      
      
    <a class="menuItem " href="/help/">Help</a>
    
      
      
      
    <a class="menuItem " href="/contribute/">Contribute</a>
    
      
      
      
    <a class="menuItem " href="/find/"><i class="fas fa-search fa-lg"></i> </a>
    
      
      
      
    <a class="menuItem " href="https://github.com/tidymodels/"><i class="fab fa-github fa-lg"></i></a>
    
  </div>
</div>

            </div>
          </div>
        </div>
</head>
<body>


 




<div class="band padForHeader pushFooter">
  <div class="bandContent">
    <div class="full splitColumns withMobileMargins">

      
<div class="column25-left hideOnMobile">
  <div class="section">
    <div class="section">
      <div class="start sectionTitle">
          
          <a class = "sectionTitle " href="/start/">
          Get Started
          
          </a>
      </div>
    </div>
  
    <div class="section">
        <div class="sectionTitle">1&nbsp&nbsp<a class = "sectionTitle " href="/start/models/">Build a model</a>
        </div>
    </div>
    
    <div class="section">
        <div class="sectionTitle">2&nbsp&nbsp<a class = "sectionTitle " href="/start/recipes/">Preprocess your data with recipes</a>
        </div>
    </div>
    
    <div class="section">
        <div class="sectionTitle">3&nbsp&nbsp<a class = "sectionTitle " href="/start/resampling/">Evaluate your model with resampling</a>
        </div>
    </div>
    
    <div class="section">
        <div class="sectionTitle">4&nbsp&nbsp<a class = "sectionTitle current" href="/start/tuning/">Tune model parameters</a>
        </div>
    </div>
    
    <div class="section">
        <div class="sectionTitle">5&nbsp&nbsp<a class = "sectionTitle " href="/start/case-study/">A predictive modeling case study</a>
        </div>
    </div>
    
  </div>
  
   
  
    <a class="help-link" href="https://www.tidymodels.org/help/" ><div class="help"> Stuck? Confused? Ask for help. </div></a>

  

</div>

      
      <div class="column75">

      <h1 class="article-title">4&nbsp;&nbsp;&nbsp;Tune model parameters</h1>
      
      <div class="tags-list">
      <i class="fas fa-box-open" style="color:#1a162dde;"></i>&nbsp;
      <h1 class="learning-objective">Tidymodels packages: </h1>
      
        <a href="https://www.tidymodels.org/tags/rsample/">rsample</a>, 
        <a href="https://www.tidymodels.org/tags/parsnip/">parsnip</a>, 
        <a href="https://www.tidymodels.org/tags/tune/">tune</a>, 
        <a href="https://www.tidymodels.org/tags/dials/">dials</a>, 
        <a href="https://www.tidymodels.org/tags/workflows/">workflows</a>, 
        <a href="https://www.tidymodels.org/tags/yardstick/">yardstick</a></div>
        
      <div class="section">
        <div class="listItem learn-top-nav">
          <div class="tutorial"><nav id="TableOfContents">
  <ul>
    <li><a href="#intro">Introduction</a></li>
    <li><a href="#data">The cell image data, revisited</a></li>
    <li><a href="#why-tune">Predicting image segmentation, but better</a></li>
    <li><a href="#tuning">Tuning hyperparameters</a></li>
    <li><a href="#tune-grid">Model tuning with a grid</a></li>
    <li><a href="#final-model">Finalizing our model</a></li>
    <li><a href="#session-information">Session information</a></li>
  </ul>
</nav></div>
        </div>
      </div>
      
      <div class="article-content">
      <h2 id="intro">Introduction&nbsp;<a class="hanchor" ariaLabel="Anchor" href="#intro">🔗&#xFE0E;</a> </h2>
<p>Some model parameters cannot be learned directly from a data set during model training; these kinds of parameters are called <strong>hyperparameters</strong>. Some examples of hyperparameters include the number of predictors that are sampled at splits in a tree-based model (we call this <code>mtry</code> in tidymodels) or the learning rate in a boosted tree model (we call this <code>learn_rate</code>). Instead of learning these kinds of hyperparameters during model training, we can <em>estimate</em> the best values for these values by training many models on resampled data sets and exploring how well all these models perform. This process is called <strong>tuning</strong>.</p>
<p>To use code in this article,  you will need to install the following packages: rpart, rpart.plot, tidymodels, and vip.</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#00f">library</span>(tidymodels)  <span style="color:#408080;font-style:italic"># for the tune package, along with the rest of tidymodels</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Helper packages</span>
</span></span><span style="display:flex;"><span><span style="color:#00f">library</span>(rpart.plot)  <span style="color:#408080;font-style:italic"># for visualizing a decision tree</span>
</span></span><span style="display:flex;"><span><span style="color:#00f">library</span>(vip)         <span style="color:#408080;font-style:italic"># for variable importance plots</span>
</span></span></code></pre></div><p> Alternatively, open an interactive version of this article in your browser: </p>

<a href="https://rstudio.cloud/project/2674862">
  <button class="test-drive-btn"><i class="fa fa-cloud"></i> Test Drive on RStudio Cloud</button>
</a>

<h2 id="data">The cell image data, revisited&nbsp;<a class="hanchor" ariaLabel="Anchor" href="#data">🔗&#xFE0E;</a> </h2>
<p>In our previous <a href="/start/resampling/"><em>Evaluate your model with resampling</em></a> article, we introduced a data set of images of cells that were labeled by experts as well-segmented (<code>WS</code>) or poorly segmented (<code>PS</code>). We trained a <a href="/start/resampling/#modeling">random forest model</a> to predict which images are segmented well vs. poorly, so that a biologist could filter out poorly segmented cell images in their analysis. We used <a href="/start/resampling/#resampling">resampling</a> to estimate the performance of our model on this data.</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#00f">data</span>(cells, package <span style="color:#666">=</span> <span style="color:#ba2121">&#34;modeldata&#34;</span>)
</span></span><span style="display:flex;"><span>cells
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; # A tibble: 2,019 × 58</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;   case  class angle_ch_1 area_ch_1 avg_inten_ch_1 avg_inten_ch_2 avg_inten_ch_3</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;   &lt;fct&gt; &lt;fct&gt;      &lt;dbl&gt;     &lt;int&gt;          &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 1 Test  PS        143.         185           15.7           4.95           9.55</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 2 Train PS        134.         819           31.9         207.            69.9 </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 3 Train WS        107.         431           28.0         116.            63.9 </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 4 Train PS         69.2        298           19.5         102.            28.2 </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 5 Test  PS          2.89       285           24.3         112.            20.5 </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; # … with 2,014 more rows, and 51 more variables: avg_inten_ch_4 &lt;dbl&gt;,</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; #   convex_hull_area_ratio_ch_1 &lt;dbl&gt;, convex_hull_perim_ratio_ch_1 &lt;dbl&gt;,</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; #   diff_inten_density_ch_1 &lt;dbl&gt;, diff_inten_density_ch_3 &lt;dbl&gt;, …</span>
</span></span></code></pre></div><h2 id="why-tune">Predicting image segmentation, but better&nbsp;<a class="hanchor" ariaLabel="Anchor" href="#why-tune">🔗&#xFE0E;</a> </h2>
<p>Random forest models are a tree-based ensemble method, and typically perform well with <a href="https://bradleyboehmke.github.io/HOML/random-forest.html#out-of-the-box-performance">default hyperparameters</a>. However, the accuracy of some other tree-based models, such as <a href="https://en.wikipedia.org/wiki/Gradient_boosting#Gradient_tree_boosting">boosted tree models</a> or <a href="https://en.wikipedia.org/wiki/Decision_tree">decision tree models</a>, can be sensitive to the values of hyperparameters. In this article, we will train a <strong>decision tree</strong> model. There are several hyperparameters for decision tree models that can be tuned for better performance. Let&rsquo;s explore:</p>
<ul>
<li>the complexity parameter (which we call <code>cost_complexity</code> in tidymodels) for the tree, and</li>
<li>the maximum <code>tree_depth</code>.</li>
</ul>
<p>Tuning these hyperparameters can improve model performance because decision tree models are prone to <a href="https://bookdown.org/max/FES/important-concepts.html#overfitting">overfitting</a>. This happens because single tree models tend to fit the training data <em>too well</em> — so well, in fact, that they over-learn patterns present in the training data that end up being detrimental when predicting new data.</p>
<p>We will tune the model hyperparameters to avoid overfitting. Tuning the value of <code>cost_complexity</code> helps by <a href="https://bradleyboehmke.github.io/HOML/DT.html#pruning">pruning</a> back our tree. It adds a cost, or penalty, to error rates of more complex trees; a cost closer to zero decreases the number tree nodes pruned and is more likely to result in an overfit tree. However, a high cost increases the number of tree nodes pruned and can result in the opposite problem—an underfit tree. Tuning <code>tree_depth</code>, on the other hand, helps by <a href="https://bradleyboehmke.github.io/HOML/DT.html#early-stopping">stopping</a>  our tree from growing after it reaches a certain depth. We want to tune these hyperparameters to find what those two values should be for our model to do the best job predicting image segmentation.</p>
<p>Before we start the tuning process, we split our data into training and testing sets, just like when we trained the model with one default set of hyperparameters. As <a href="/start/resampling/">before</a>, we can use <code>strata = class</code> if we want our training and testing sets to be created using stratified sampling so that both have the same proportion of both kinds of segmentation.</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#00f">set.seed</span>(<span style="color:#666">123</span>)
</span></span><span style="display:flex;"><span>cell_split <span style="color:#666">&lt;-</span> <span style="color:#00f">initial_split</span>(cells <span style="color:#666">%&gt;%</span> <span style="color:#00f">select</span>(<span style="color:#666">-</span>case), 
</span></span><span style="display:flex;"><span>                            strata <span style="color:#666">=</span> class)
</span></span><span style="display:flex;"><span>cell_train <span style="color:#666">&lt;-</span> <span style="color:#00f">training</span>(cell_split)
</span></span><span style="display:flex;"><span>cell_test  <span style="color:#666">&lt;-</span> <span style="color:#00f">testing</span>(cell_split)
</span></span></code></pre></div><p>We use the training data for tuning the model.</p>
<h2 id="tuning">Tuning hyperparameters&nbsp;<a class="hanchor" ariaLabel="Anchor" href="#tuning">🔗&#xFE0E;</a> </h2>
<p>Let’s start with the parsnip package, using a <a href="https://parsnip.tidymodels.org/reference/decision_tree.html"><code>decision_tree()</code></a> model with the <a href="https://cran.r-project.org/web/packages/rpart/index.html">rpart</a> engine. To tune the decision tree hyperparameters <code>cost_complexity</code> and <code>tree_depth</code>, we create a model specification that identifies which hyperparameters we plan to tune.</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>tune_spec <span style="color:#666">&lt;-</span> 
</span></span><span style="display:flex;"><span>  <span style="color:#00f">decision_tree</span>(
</span></span><span style="display:flex;"><span>    cost_complexity <span style="color:#666">=</span> <span style="color:#00f">tune</span>(),
</span></span><span style="display:flex;"><span>    tree_depth <span style="color:#666">=</span> <span style="color:#00f">tune</span>()
</span></span><span style="display:flex;"><span>  ) <span style="color:#666">%&gt;%</span> 
</span></span><span style="display:flex;"><span>  <span style="color:#00f">set_engine</span>(<span style="color:#ba2121">&#34;rpart&#34;</span>) <span style="color:#666">%&gt;%</span> 
</span></span><span style="display:flex;"><span>  <span style="color:#00f">set_mode</span>(<span style="color:#ba2121">&#34;classification&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tune_spec
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Decision Tree Model Specification (classification)</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Main Arguments:</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;   cost_complexity = tune()</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;   tree_depth = tune()</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Computational engine: rpart</span>
</span></span></code></pre></div><p>Think of <code>tune()</code> here as a placeholder. After the tuning process, we will select a single numeric value for each of these hyperparameters. For now, we specify our parsnip model object and identify the hyperparameters we will <code>tune()</code>.</p>
<p>We can&rsquo;t train this specification on a single data set (such as the entire training set) and learn what the hyperparameter values should be, but we <em>can</em> train many models using resampled data and see which models turn out best. We can create a regular grid of values to try using some convenience functions for each hyperparameter:</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>tree_grid <span style="color:#666">&lt;-</span> <span style="color:#00f">grid_regular</span>(<span style="color:#00f">cost_complexity</span>(),
</span></span><span style="display:flex;"><span>                          <span style="color:#00f">tree_depth</span>(),
</span></span><span style="display:flex;"><span>                          levels <span style="color:#666">=</span> <span style="color:#666">5</span>)
</span></span></code></pre></div><p>The function <a href="https://dials.tidymodels.org/reference/grid_regular.html"><code>grid_regular()</code></a> is from the <a href="https://dials.tidymodels.org/">dials</a> package. It chooses sensible values to try for each hyperparameter; here, we asked for 5 of each. Since we have two to tune, <code>grid_regular()</code> returns 5 <code>\(\times\)</code> 5 = 25 different possible tuning combinations to try in a tidy tibble format.</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>tree_grid
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; # A tibble: 25 × 2</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;    cost_complexity tree_depth</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;              &lt;dbl&gt;      &lt;int&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  1    0.0000000001          1</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  2    0.0000000178          1</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  3    0.00000316            1</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  4    0.000562              1</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  5    0.1                   1</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  6    0.0000000001          4</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  7    0.0000000178          4</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  8    0.00000316            4</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  9    0.000562              4</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 10    0.1                   4</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; # … with 15 more rows</span>
</span></span></code></pre></div><p>Here, you can see all 5 values of <code>cost_complexity</code> ranging up to 0.1. These values get repeated for each of the 5 values of <code>tree_depth</code>:</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>tree_grid <span style="color:#666">%&gt;%</span> 
</span></span><span style="display:flex;"><span>  <span style="color:#00f">count</span>(tree_depth)
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; # A tibble: 5 × 2</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;   tree_depth     n</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;        &lt;int&gt; &lt;int&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 1          1     5</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 2          4     5</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 3          8     5</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 4         11     5</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 5         15     5</span>
</span></span></code></pre></div><p>Armed with our grid filled with 25 candidate decision tree models, let&rsquo;s create <a href="/start/resampling/">cross-validation folds</a> for tuning:</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#00f">set.seed</span>(<span style="color:#666">234</span>)
</span></span><span style="display:flex;"><span>cell_folds <span style="color:#666">&lt;-</span> <span style="color:#00f">vfold_cv</span>(cell_train)
</span></span></code></pre></div><p>Tuning in tidymodels requires a resampled object created with the <a href="https://rsample.tidymodels.org/">rsample</a> package.</p>
<h2 id="tune-grid">Model tuning with a grid&nbsp;<a class="hanchor" ariaLabel="Anchor" href="#tune-grid">🔗&#xFE0E;</a> </h2>
<p>We are ready to tune! Let&rsquo;s use <a href="https://tune.tidymodels.org/reference/tune_grid.html"><code>tune_grid()</code></a> to fit models at all the different values we chose for each tuned hyperparameter. There are several options for building the object for tuning:</p>
<ul>
<li>
<p>Tune a model specification along with a recipe or model, or</p>
</li>
<li>
<p>Tune a <a href="https://workflows.tidymodels.org/"><code>workflow()</code></a> that bundles together a model specification and a recipe or model preprocessor.</p>
</li>
</ul>
<p>Here we use a <code>workflow()</code> with a straightforward formula; if this model required more involved data preprocessing, we could use <code>add_recipe()</code> instead of <code>add_formula()</code>.</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#00f">set.seed</span>(<span style="color:#666">345</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tree_wf <span style="color:#666">&lt;-</span> <span style="color:#00f">workflow</span>() <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">add_model</span>(tune_spec) <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">add_formula</span>(class <span style="color:#666">~</span> .)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tree_res <span style="color:#666">&lt;-</span> 
</span></span><span style="display:flex;"><span>  tree_wf <span style="color:#666">%&gt;%</span> 
</span></span><span style="display:flex;"><span>  <span style="color:#00f">tune_grid</span>(
</span></span><span style="display:flex;"><span>    resamples <span style="color:#666">=</span> cell_folds,
</span></span><span style="display:flex;"><span>    grid <span style="color:#666">=</span> tree_grid
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tree_res
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; # Tuning results</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; # 10-fold cross-validation </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; # A tibble: 10 × 4</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;    splits             id     .metrics          .notes          </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;    &lt;list&gt;             &lt;chr&gt;  &lt;list&gt;            &lt;list&gt;          </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  1 &lt;split [1362/152]&gt; Fold01 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  2 &lt;split [1362/152]&gt; Fold02 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  3 &lt;split [1362/152]&gt; Fold03 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  4 &lt;split [1362/152]&gt; Fold04 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  5 &lt;split [1363/151]&gt; Fold05 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  6 &lt;split [1363/151]&gt; Fold06 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  7 &lt;split [1363/151]&gt; Fold07 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  8 &lt;split [1363/151]&gt; Fold08 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  9 &lt;split [1363/151]&gt; Fold09 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 10 &lt;split [1363/151]&gt; Fold10 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt;</span>
</span></span></code></pre></div><p>Once we have our tuning results, we can both explore them through visualization and then select the best result. The function <code>collect_metrics()</code> gives us a tidy tibble with all the results. We had 25 candidate models and two metrics, <code>accuracy</code> and <code>roc_auc</code>, and we get a row for each <code>.metric</code> and model.</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>tree_res <span style="color:#666">%&gt;%</span> 
</span></span><span style="display:flex;"><span>  <span style="color:#00f">collect_metrics</span>()
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; # A tibble: 50 × 8</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;    cost_complexity tree_depth .metric  .estimator  mean     n std_err .config   </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;              &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;     </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  1    0.0000000001          1 accuracy binary     0.732    10  0.0148 Preproces…</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  2    0.0000000001          1 roc_auc  binary     0.777    10  0.0107 Preproces…</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  3    0.0000000178          1 accuracy binary     0.732    10  0.0148 Preproces…</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  4    0.0000000178          1 roc_auc  binary     0.777    10  0.0107 Preproces…</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  5    0.00000316            1 accuracy binary     0.732    10  0.0148 Preproces…</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  6    0.00000316            1 roc_auc  binary     0.777    10  0.0107 Preproces…</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  7    0.000562              1 accuracy binary     0.732    10  0.0148 Preproces…</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  8    0.000562              1 roc_auc  binary     0.777    10  0.0107 Preproces…</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  9    0.1                   1 accuracy binary     0.732    10  0.0148 Preproces…</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 10    0.1                   1 roc_auc  binary     0.777    10  0.0107 Preproces…</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; # … with 40 more rows</span>
</span></span></code></pre></div><p>We might get more out of plotting these results:</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>tree_res <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">collect_metrics</span>() <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">mutate</span>(tree_depth <span style="color:#666">=</span> <span style="color:#00f">factor</span>(tree_depth)) <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">ggplot</span>(<span style="color:#00f">aes</span>(cost_complexity, mean, color <span style="color:#666">=</span> tree_depth)) <span style="color:#666">+</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">geom_line</span>(size <span style="color:#666">=</span> <span style="color:#666">1.5</span>, alpha <span style="color:#666">=</span> <span style="color:#666">0.6</span>) <span style="color:#666">+</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">geom_point</span>(size <span style="color:#666">=</span> <span style="color:#666">2</span>) <span style="color:#666">+</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">facet_wrap</span>(<span style="color:#666">~</span> .metric, scales <span style="color:#666">=</span> <span style="color:#ba2121">&#34;free&#34;</span>, nrow <span style="color:#666">=</span> <span style="color:#666">2</span>) <span style="color:#666">+</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">scale_x_log10</span>(labels <span style="color:#666">=</span> scales<span style="color:#666">::</span><span style="color:#00f">label_number</span>()) <span style="color:#666">+</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">scale_color_viridis_d</span>(option <span style="color:#666">=</span> <span style="color:#ba2121">&#34;plasma&#34;</span>, begin <span style="color:#666">=</span> <span style="color:#666">.9</span>, end <span style="color:#666">=</span> <span style="color:#666">0</span>)
</span></span></code></pre></div><img src="figs/best-tree-1.svg" width="768" />
<p>We can see that our &ldquo;stubbiest&rdquo; tree, with a depth of 1, is the worst model according to both metrics and across all candidate values of <code>cost_complexity</code>. Our deepest tree, with a depth of 15, did better. However, the best tree seems to be between these values with a tree depth of 4. The <a href="https://tune.tidymodels.org/reference/show_best.html"><code>show_best()</code></a> function shows us the top 5 candidate models by default:</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>tree_res <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">show_best</span>(<span style="color:#ba2121">&#34;accuracy&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; # A tibble: 5 × 8</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;   cost_complexity tree_depth .metric  .estimator  mean     n std_err .config    </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;      </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 1    0.0000000001          4 accuracy binary     0.807    10  0.0119 Preprocess…</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 2    0.0000000178          4 accuracy binary     0.807    10  0.0119 Preprocess…</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 3    0.00000316            4 accuracy binary     0.807    10  0.0119 Preprocess…</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 4    0.000562              4 accuracy binary     0.807    10  0.0119 Preprocess…</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 5    0.1                   4 accuracy binary     0.786    10  0.0124 Preprocess…</span>
</span></span></code></pre></div><p>We can also use the <a href="https://tune.tidymodels.org/reference/show_best.html"><code>select_best()</code></a> function to pull out the single set of hyperparameter values for our best decision tree model:</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>best_tree <span style="color:#666">&lt;-</span> tree_res <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">select_best</span>(<span style="color:#ba2121">&#34;accuracy&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>best_tree
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; # A tibble: 1 × 3</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;   cost_complexity tree_depth .config              </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;                </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 1    0.0000000001          4 Preprocessor1_Model06</span>
</span></span></code></pre></div><p>These are the values for <code>tree_depth</code> and <code>cost_complexity</code> that maximize accuracy in this data set of cell images.</p>
<h2 id="final-model">Finalizing our model&nbsp;<a class="hanchor" ariaLabel="Anchor" href="#final-model">🔗&#xFE0E;</a> </h2>
<p>We can update (or &ldquo;finalize&rdquo;) our workflow object <code>tree_wf</code> with the values from <code>select_best()</code>.</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>final_wf <span style="color:#666">&lt;-</span> 
</span></span><span style="display:flex;"><span>  tree_wf <span style="color:#666">%&gt;%</span> 
</span></span><span style="display:flex;"><span>  <span style="color:#00f">finalize_workflow</span>(best_tree)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>final_wf
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; ══ Workflow ══════════════════════════════════════════════════════════</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Preprocessor: Formula</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Model: decision_tree()</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; ── Preprocessor ──────────────────────────────────────────────────────</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; class ~ .</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; ── Model ─────────────────────────────────────────────────────────────</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Decision Tree Model Specification (classification)</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Main Arguments:</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;   cost_complexity = 1e-10</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;   tree_depth = 4</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Computational engine: rpart</span>
</span></span></code></pre></div><p>Our tuning is done!</p>
<h3 id="the-last-fit">The last fit</h3>
<p>Finally, let&rsquo;s fit this final model to the training data and use our test data to estimate the model performance we expect to see with new data. We can use the function <a href="https://tune.tidymodels.org/reference/last_fit.html"><code>last_fit()</code></a> with our finalized model; this function <em>fits</em> the finalized model on the full training data set and <em>evaluates</em> the finalized model on the testing data.</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>final_fit <span style="color:#666">&lt;-</span> 
</span></span><span style="display:flex;"><span>  final_wf <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">last_fit</span>(cell_split) 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>final_fit <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">collect_metrics</span>()
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; # A tibble: 2 × 4</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;   .metric  .estimator .estimate .config             </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 1 accuracy binary         0.802 Preprocessor1_Model1</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 2 roc_auc  binary         0.840 Preprocessor1_Model1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>final_fit <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">collect_predictions</span>() <span style="color:#666">%&gt;%</span> 
</span></span><span style="display:flex;"><span>  <span style="color:#00f">roc_curve</span>(class, .pred_PS) <span style="color:#666">%&gt;%</span> 
</span></span><span style="display:flex;"><span>  <span style="color:#00f">autoplot</span>()
</span></span></code></pre></div><img src="figs/last-fit-1.svg" width="672" />
<p>The performance metrics from the test set indicate that we did not overfit during our tuning procedure.</p>
<p>The <code>final_fit</code> object contains a finalized, fitted workflow that you can use for predicting on new data or further understanding the results. You may want to extract this object, using <a href="https://tune.tidymodels.org/reference/extract-tune.html">one of the <code>extract_</code> helper functions</a>.</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>final_tree <span style="color:#666">&lt;-</span> <span style="color:#00f">extract_workflow</span>(final_fit)
</span></span><span style="display:flex;"><span>final_tree
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; ══ Workflow [trained] ════════════════════════════════════════════════</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Preprocessor: Formula</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Model: decision_tree()</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; ── Preprocessor ──────────────────────────────────────────────────────</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; class ~ .</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; ── Model ─────────────────────────────────────────────────────────────</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; n= 1514 </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; node), split, n, loss, yval, (yprob)</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;       * denotes terminal node</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  1) root 1514 539 PS (0.64398943 0.35601057)  </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;    2) total_inten_ch_2&lt; 41732.5 642  33 PS (0.94859813 0.05140187)  </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;      4) shape_p_2_a_ch_1&gt;=1.251801 631  27 PS (0.95721078 0.04278922) *</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;      5) shape_p_2_a_ch_1&lt; 1.251801 11   5 WS (0.45454545 0.54545455) *</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;    3) total_inten_ch_2&gt;=41732.5 872 366 WS (0.41972477 0.58027523)  </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;      6) fiber_width_ch_1&lt; 11.37318 406 160 PS (0.60591133 0.39408867)  </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;       12) avg_inten_ch_1&lt; 145.4883 293  85 PS (0.70989761 0.29010239) *</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;       13) avg_inten_ch_1&gt;=145.4883 113  38 WS (0.33628319 0.66371681)  </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;         26) total_inten_ch_3&gt;=57919.5 33  10 PS (0.69696970 0.30303030) *</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;         27) total_inten_ch_3&lt; 57919.5 80  15 WS (0.18750000 0.81250000) *</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;      7) fiber_width_ch_1&gt;=11.37318 466 120 WS (0.25751073 0.74248927)  </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;       14) eq_ellipse_oblate_vol_ch_1&gt;=1673.942 30   8 PS (0.73333333 0.26666667)  </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;         28) var_inten_ch_3&gt;=41.10858 20   2 PS (0.90000000 0.10000000) *</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;         29) var_inten_ch_3&lt; 41.10858 10   4 WS (0.40000000 0.60000000) *</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;       15) eq_ellipse_oblate_vol_ch_1&lt; 1673.942 436  98 WS (0.22477064 0.77522936) *</span>
</span></span></code></pre></div><p>We can create a visualization of the decision tree using another helper function to extract the underlying engine-specific fit.</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>final_tree <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">extract_fit_engine</span>() <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">rpart.plot</span>(roundint <span style="color:#666">=</span> <span style="color:#008000;font-weight:bold">FALSE</span>)
</span></span></code></pre></div><img src="figs/rpart-plot-1.svg" width="768" />
<p>Perhaps we would also like to understand what variables are important in this final model. We can use the <a href="https://koalaverse.github.io/vip/">vip</a> package to estimate variable importance <a href="https://koalaverse.github.io/vip/reference/vi_model.html#details">based on the model&rsquo;s structure</a>.</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#00f">library</span>(vip)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>final_tree <span style="color:#666">%&gt;%</span> 
</span></span><span style="display:flex;"><span>  <span style="color:#00f">extract_fit_parsnip</span>() <span style="color:#666">%&gt;%</span> 
</span></span><span style="display:flex;"><span>  <span style="color:#00f">vip</span>()
</span></span></code></pre></div><img src="figs/vip-1.svg" width="576" />
<p>These are the automated image analysis measurements that are the most important in driving segmentation quality predictions.</p>
<p>We leave it to the reader to explore whether you can tune a different decision tree hyperparameter. You can explore the <a href="/find/parsnip/#models">reference docs</a>, or use the <code>args()</code> function to see which parsnip object arguments are available:</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#00f">args</span>(decision_tree)
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; function (mode = &#34;unknown&#34;, engine = &#34;rpart&#34;, cost_complexity = NULL, </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;     tree_depth = NULL, min_n = NULL) </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; NULL</span>
</span></span></code></pre></div><p>You could tune the other hyperparameter we didn&rsquo;t use here, <code>min_n</code>, which sets the minimum <code>n</code> to split at any node. This is another early stopping method for decision trees that can help prevent overfitting. Use this <a href="/find/parsnip/#model-args">searchable table</a> to find the original argument for <code>min_n</code> in the rpart package (<a href="https://stat.ethz.ch/R-manual/R-devel/library/rpart/html/rpart.control.html">hint</a>). See whether you can tune a different combination of hyperparameters and/or values to improve a tree&rsquo;s ability to predict cell segmentation quality.</p>
<h2 id="session-information">Session information&nbsp;<a class="hanchor" ariaLabel="Anchor" href="#session-information">🔗&#xFE0E;</a> </h2>
<pre tabindex="0"><code>#&gt; ─ Session info ─────────────────────────────────────────────────────
#&gt;  setting  value
#&gt;  version  R version 4.1.1 (2021-08-10)
#&gt;  os       macOS Monterey 12.2.1
#&gt;  system   aarch64, darwin20
#&gt;  ui       X11
#&gt;  language (EN)
#&gt;  collate  en_US.UTF-8
#&gt;  ctype    en_US.UTF-8
#&gt;  tz       America/Denver
#&gt;  date     2022-03-23
#&gt;  pandoc   2.17.1.1 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/ (via rmarkdown)
#&gt; 
#&gt; ─ Packages ─────────────────────────────────────────────────────────
#&gt;  package    * version date (UTC) lib source
#&gt;  broom      * 0.7.12  2022-01-28 [1] CRAN (R 4.1.1)
#&gt;  dials      * 0.1.0   2022-01-31 [1] CRAN (R 4.1.1)
#&gt;  dplyr      * 1.0.8   2022-02-08 [1] CRAN (R 4.1.1)
#&gt;  ggplot2    * 3.3.5   2021-06-25 [1] CRAN (R 4.1.0)
#&gt;  infer      * 1.0.0   2021-08-13 [1] CRAN (R 4.1.1)
#&gt;  parsnip    * 0.2.1   2022-03-17 [1] CRAN (R 4.1.1)
#&gt;  purrr      * 0.3.4   2020-04-17 [1] CRAN (R 4.1.0)
#&gt;  recipes    * 0.2.0   2022-02-18 [1] CRAN (R 4.1.1)
#&gt;  rlang        1.0.2   2022-03-04 [1] CRAN (R 4.1.1)
#&gt;  rpart      * 4.1.16  2022-01-24 [1] CRAN (R 4.1.1)
#&gt;  rpart.plot * 3.1.0   2021-07-24 [1] CRAN (R 4.1.0)
#&gt;  rsample    * 0.1.1   2021-11-08 [1] CRAN (R 4.1.1)
#&gt;  tibble     * 3.1.6   2021-11-07 [1] CRAN (R 4.1.1)
#&gt;  tidymodels * 0.2.0   2022-03-19 [1] CRAN (R 4.1.1)
#&gt;  tune       * 0.2.0   2022-03-19 [1] CRAN (R 4.1.1)
#&gt;  vip        * 0.3.2   2020-12-17 [1] CRAN (R 4.1.0)
#&gt;  workflows  * 0.2.6   2022-03-18 [1] CRAN (R 4.1.1)
#&gt;  yardstick  * 0.0.9   2021-11-22 [1] CRAN (R 4.1.1)
#&gt; 
#&gt;  [1] /Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/library
#&gt; 
#&gt; ────────────────────────────────────────────────────────────────────
</code></pre>

      </div>

    <div class="article-footer">
      
      <div style="float:left">
      
        <div class='itemTitle' align="left" style='font-size:.8em; line-height:2em'>Previous</div>
        <a href="/start/resampling/">Evaluate your model with resampling</a>
      
      </div>
      
      
      <div style="float:right">
      
      <div class='itemTitle' align="right" style='font-size:.8em; line-height:2em;'>Next</div>
        <a href="/start/case-study/">A predictive modeling case study</a>
      
      
      </div>
     </div> 
      

      </div>

    </div>
  </div>  
</div> 


        <div id="rStudioFooter" class="band">
          <div class="bandContent">
            <div id="copyright">
              
              
              Proudly supported by <a class="rstudioLogo" href="https://www.rstudio.com/"></a>
              
            </div>
            <div id="logos">
              
              
            </div>
            
            <span class="float-right" aria-hidden="true">
              <a href="#" class="back-to-top">
                <span class="button_icon">
                  <i class="fas fa-chevron-up fa-2x"></i>
                </span>
              </a>
            </span>
            
          </div>
        </div>

      </div>  
    </div>  

    

    
<script src="/js/math-code.js"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true
  }
});
</script>
<script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-20375833-29', 'auto');
	
	ga('send', 'pageview');
}
</script>

  </body>
</html>

</body>
</html>
