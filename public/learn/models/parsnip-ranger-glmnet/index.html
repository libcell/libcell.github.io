<!DOCTYPE html>
<html>
<head>
<!DOCTYPE html>
<html lang="en-us">



<link rel="stylesheet" href="/css/fonts.css">
<link rel="stylesheet" href="/css/main-site.css">
<link rel="stylesheet" href="/css/fa5-all.css">
<style type="text/css">
    body {
	background-color: #ffffff;
	color: #404040
}

/* Links */

a {
  color: #CA225E;
}

a:hover {
  color: #cc3168;
}

/* Landing page content bands */

#homeContent .band.first {
  background-color: #ffffff
}

#homeContent .band.second {
  background-color: #fcfcfc
}

#homeContent .band.third {
  background-color: #ffffff
}

/* Top navigation bar menu */

#rStudioHeader {
  background-color: #ffffff;
  color: black;
}

#rStudioHeader .productName {
  color: #CA225E
}

#rStudioHeader .productName:hover {
  color: #00000075
}

#rStudioHeader #menu .menuItem.a {
  background-color: #75aadb;
  color: black;
}

#rStudioHeader #menu .menuItem:hover {
  background-color: white;
  color: #CA225E;
}

#rStudioHeader #menu .menuItem.current {
  background-color: #fcfcfc;
  color: #CA225E;
  text-decoration: none;
}

/* Footer */

#rStudioFooter.band {
  background-color: #CA225E40;
}

#rStudioFooter .bandContent #copyright {
  color: #CA225E;
}

/* Tables */

table tbody tr:nth-child(even){
  background-color: #fcfcfc;
}

table tbody tr:nth-child(odd){
  background-color: #1a162d10;
}

.latest {
  border-top: .5em solid <no value>;
}
</style>

  <link rel="stylesheet" href="/css/tm.css">




<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<meta name="apple-mobile-web-app-capable" content="yes" />

<meta name="og:image" content="https://www.tidymodels.org/images/feature_summary_large_image.jpg" >

  <meta property="twitter:card" content="summary_large_image">

<meta name="twitter:image" content="https://www.tidymodels.org/images/feature_summary_large_image.jpg" ><meta name="generator" content="Hugo 0.96.0" />

<meta property="og:type" content="website"><title>Learn - Regression models two ways</title>
    <meta property="og:title" content="Learn - Regression models two ways">
    
    
    
    
    <meta property="description" content="Create and train different kinds of regression models with different computational engines.
">
    <meta property="og:description" content="Create and train different kinds of regression models with different computational engines.
">



<link rel="apple-touch-icon" sizes="180x180" href="/images/favicons/apple-touch-icon.png" />
<link rel="icon" type="image/png" sizes="32x32" href="/images/favicons/favicon-32x32.png" />
<link rel="icon" type="image/png" sizes="16x16" href="/images/favicons/favicon-16x16.png" />
<link rel="manifest" href="/images/favicons/site.webmanifest" />
<link rel="mask-icon" href="/images/favicons/safari-pinned-tab.svg" />
<link rel="shortcut icon" href="/images/favicons/favicon.ico" />
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" href="/images/favicons/browserconfig.xml" >



<script type="text/javascript" src="/js/jquery-3.5.1.min.js"></script>
<script type="text/javascript" src="/js/site.js"></script>


  <script type="text/javascript" src="/js/tm.js"></script>


<link rel="icon" href="/images/favicon.ico" />


<script defer data-domain="tidymodels.org,all.tidymodels.org" src="https://plausible.io/js/plausible.js"></script>


<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script>


<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>



  <body>
    <div id="appTidyverseSite" class="shrinkHeader alwaysShrinkHeader">
      <div id="main">
        
        <div id="rStudioHeader">
          <div class="band">
            <div class="innards bandContent">
              <div>
                <a class="productName" href="/">Tidymodels</a>
                
              </div>
              <div id="menu">
  <div id="menuToggler"></div>
  <div id="menuItems" class="">
    
    
      
      
      
    <a class="menuItem " href="/packages/">Packages</a>
    
      
      
      
    <a class="menuItem " href="/start/">Get Started</a>
    
      
      
      
    <a class="menuItem current" href="/learn/">Learn</a>
    
      
      
      
    <a class="menuItem " href="/help/">Help</a>
    
      
      
      
    <a class="menuItem " href="/contribute/">Contribute</a>
    
      
      
      
    <a class="menuItem " href="/find/"><i class="fas fa-search fa-lg"></i> </a>
    
      
      
      
    <a class="menuItem " href="https://github.com/tidymodels/"><i class="fab fa-github fa-lg"></i></a>
    
  </div>
</div>

            </div>
          </div>
        </div>
</head>
<body>


 




<div class="band padForHeader pushFooter">
  <div class="bandContent">
    <div class="full splitColumns withMobileMargins">
      <div class="column75">
        
        <div class="section">
          <div class="sectionTitle">
            <a href="/learn/">
              <i class="fas fa-chevron-left"></i>&nbsp;Back to Learn
            </a>
          </div>
        </div>

      <h1 class="article-title">Regression models two ways</h1>

      
      <div class="article-header">
        </div>
        

      
      
      
      
        </p>
      
        
      <div class="learning-objective-container">
        <h2 class="learning-objective">Learning objective</h2>
        <p class="single-learning-objective-text">Create and train different kinds of regression models with different computational engines.</p>
      </div>
      

      <div class="article-content">
      <h2 id="introduction">Introduction</h2>
<p>To use the code in this article, you will need to install the following packages: glmnet, randomForest, ranger, and tidymodels.</p>
<p>We can create regression models with the tidymodels package <a href="https://parsnip.tidymodels.org/">parsnip</a> to predict continuous or numeric quantities. Here, let&rsquo;s first fit a random forest model, which does <em>not</em> require all numeric input (see discussion <a href="https://bookdown.org/max/FES/categorical-trees.html">here</a>) and discuss how to use <code>fit()</code> and <code>fit_xy()</code>, as well as <em>data descriptors</em>.</p>
<p>Second, let&rsquo;s fit a regularized linear regression model to demonstrate how to move between different types of models using parsnip.</p>
<h2 id="the-ames-housing-data">The Ames housing data</h2>
<p>We&rsquo;ll use the Ames housing data set to demonstrate how to create regression models using parsnip. First, set up the data set and create a simple training/test set split:</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#00f">library</span>(tidymodels)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00f">data</span>(ames)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00f">set.seed</span>(<span style="color:#666">4595</span>)
</span></span><span style="display:flex;"><span>data_split <span style="color:#666">&lt;-</span> <span style="color:#00f">initial_split</span>(ames, strata <span style="color:#666">=</span> <span style="color:#ba2121">&#34;Sale_Price&#34;</span>, prop <span style="color:#666">=</span> <span style="color:#666">0.75</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ames_train <span style="color:#666">&lt;-</span> <span style="color:#00f">training</span>(data_split)
</span></span><span style="display:flex;"><span>ames_test  <span style="color:#666">&lt;-</span> <span style="color:#00f">testing</span>(data_split)
</span></span></code></pre></div><p>The use of the test set here is <em>only for illustration</em>; normally in a data analysis these data would be saved to the very end after many models have been evaluated.</p>
<h2 id="random-forest">Random forest</h2>
<p>We&rsquo;ll start by fitting a random forest model to a small set of parameters. Let&rsquo;s create a model with the predictors <code>Longitude</code>, <code>Latitude</code>, <code>Lot_Area</code>, <code>Neighborhood</code>, and <code>Year_Sold</code>. A simple random forest model can be specified via:</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>rf_defaults <span style="color:#666">&lt;-</span> <span style="color:#00f">rand_forest</span>(mode <span style="color:#666">=</span> <span style="color:#ba2121">&#34;regression&#34;</span>)
</span></span><span style="display:flex;"><span>rf_defaults
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Random Forest Model Specification (regression)</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Computational engine: ranger</span>
</span></span></code></pre></div><p>The model will be fit with the ranger package by default. Since we didn&rsquo;t add any extra arguments to <code>fit</code>, <em>many</em> of the arguments will be set to their defaults from the function  <code>ranger::ranger()</code>. The help pages for the model function describe the default parameters and you can also use the <code>translate()</code> function to check out such details.</p>
<p>The parsnip package provides two different interfaces to fit a model:</p>
<ul>
<li>the formula interface (<code>fit()</code>), and</li>
<li>the non-formula interface (<code>fit_xy()</code>).</li>
</ul>
<p>Let&rsquo;s start with the non-formula interface:</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>preds <span style="color:#666">&lt;-</span> <span style="color:#00f">c</span>(<span style="color:#ba2121">&#34;Longitude&#34;</span>, <span style="color:#ba2121">&#34;Latitude&#34;</span>, <span style="color:#ba2121">&#34;Lot_Area&#34;</span>, <span style="color:#ba2121">&#34;Neighborhood&#34;</span>, <span style="color:#ba2121">&#34;Year_Sold&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>rf_xy_fit <span style="color:#666">&lt;-</span> 
</span></span><span style="display:flex;"><span>  rf_defaults <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">set_engine</span>(<span style="color:#ba2121">&#34;ranger&#34;</span>) <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">fit_xy</span>(
</span></span><span style="display:flex;"><span>    x <span style="color:#666">=</span> ames_train[, preds],
</span></span><span style="display:flex;"><span>    y <span style="color:#666">=</span> <span style="color:#00f">log10</span>(ames_train<span style="color:#666">$</span>Sale_Price)
</span></span><span style="display:flex;"><span>  )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>rf_xy_fit
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; parsnip model object</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Ranger result</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Call:</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  ranger::ranger(x = maybe_data_frame(x), y = y, num.threads = 1,      verbose = FALSE, seed = sample.int(10^5, 1)) </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Type:                             Regression </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Number of trees:                  500 </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Sample size:                      2197 </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Number of independent variables:  5 </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Mtry:                             2 </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Target node size:                 5 </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Variable importance mode:         none </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Splitrule:                        variance </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; OOB prediction error (MSE):       0.0085 </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; R squared (OOB):                  0.724</span>
</span></span></code></pre></div><p>The non-formula interface doesn&rsquo;t do anything to the predictors before passing them to the underlying model function. This particular model does <em>not</em> require indicator variables (sometimes called &ldquo;dummy variables&rdquo;) to be created prior to fitting the model. Note that the output shows &ldquo;Number of independent variables:  5&rdquo;.</p>
<p>For regression models, we can use the basic <code>predict()</code> method, which returns a tibble with a column named <code>.pred</code>:</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>test_results <span style="color:#666">&lt;-</span> 
</span></span><span style="display:flex;"><span>  ames_test <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">select</span>(Sale_Price) <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">mutate</span>(Sale_Price <span style="color:#666">=</span> <span style="color:#00f">log10</span>(Sale_Price)) <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">bind_cols</span>(
</span></span><span style="display:flex;"><span>    <span style="color:#00f">predict</span>(rf_xy_fit, new_data <span style="color:#666">=</span> ames_test[, preds])
</span></span><span style="display:flex;"><span>  )
</span></span><span style="display:flex;"><span>test_results <span style="color:#666">%&gt;%</span> <span style="color:#00f">slice</span>(<span style="color:#666">1</span><span style="color:#666">:</span><span style="color:#666">5</span>)
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; # A tibble: 5 × 2</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;   Sale_Price .pred</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;        &lt;dbl&gt; &lt;dbl&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 1       5.39  5.25</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 2       5.28  5.29</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 3       5.23  5.26</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 4       5.21  5.30</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 5       5.60  5.51</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># summarize performance</span>
</span></span><span style="display:flex;"><span>test_results <span style="color:#666">%&gt;%</span> <span style="color:#00f">metrics</span>(truth <span style="color:#666">=</span> Sale_Price, estimate <span style="color:#666">=</span> .pred) 
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; # A tibble: 3 × 3</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;   .metric .estimator .estimate</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 1 rmse    standard      0.0945</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 2 rsq     standard      0.733 </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 3 mae     standard      0.0629</span>
</span></span></code></pre></div><p>Note that:</p>
<ul>
<li>If the model required indicator variables, we would have to create them manually prior to using <code>fit()</code> (perhaps using the recipes package).</li>
<li>We had to manually log the outcome prior to modeling.</li>
</ul>
<p>Now, for illustration, let&rsquo;s use the formula method using some new parameter values:</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#00f">rand_forest</span>(mode <span style="color:#666">=</span> <span style="color:#ba2121">&#34;regression&#34;</span>, mtry <span style="color:#666">=</span> <span style="color:#666">3</span>, trees <span style="color:#666">=</span> <span style="color:#666">1000</span>) <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">set_engine</span>(<span style="color:#ba2121">&#34;ranger&#34;</span>) <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">fit</span>(
</span></span><span style="display:flex;"><span>    <span style="color:#00f">log10</span>(Sale_Price) <span style="color:#666">~</span> Longitude <span style="color:#666">+</span> Latitude <span style="color:#666">+</span> Lot_Area <span style="color:#666">+</span> Neighborhood <span style="color:#666">+</span> Year_Sold,
</span></span><span style="display:flex;"><span>    data <span style="color:#666">=</span> ames_train
</span></span><span style="display:flex;"><span>  )
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; parsnip model object</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Ranger result</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Call:</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~3,      x), num.trees = ~1000, num.threads = 1, verbose = FALSE,      seed = sample.int(10^5, 1)) </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Type:                             Regression </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Number of trees:                  1000 </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Sample size:                      2197 </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Number of independent variables:  5 </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Mtry:                             3 </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Target node size:                 5 </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Variable importance mode:         none </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Splitrule:                        variance </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; OOB prediction error (MSE):       0.0084 </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; R squared (OOB):                  0.727</span>
</span></span></code></pre></div><p>Suppose that we would like to use the randomForest package instead of ranger. To do so, the only part of the syntax that needs to change is the <code>set_engine()</code> argument:</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#00f">rand_forest</span>(mode <span style="color:#666">=</span> <span style="color:#ba2121">&#34;regression&#34;</span>, mtry <span style="color:#666">=</span> <span style="color:#666">3</span>, trees <span style="color:#666">=</span> <span style="color:#666">1000</span>) <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">set_engine</span>(<span style="color:#ba2121">&#34;randomForest&#34;</span>) <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">fit</span>(
</span></span><span style="display:flex;"><span>    <span style="color:#00f">log10</span>(Sale_Price) <span style="color:#666">~</span> Longitude <span style="color:#666">+</span> Latitude <span style="color:#666">+</span> Lot_Area <span style="color:#666">+</span> Neighborhood <span style="color:#666">+</span> Year_Sold,
</span></span><span style="display:flex;"><span>    data <span style="color:#666">=</span> ames_train
</span></span><span style="display:flex;"><span>  )
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; parsnip model object</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Call:</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  randomForest(x = maybe_data_frame(x), y = y, ntree = ~1000, mtry = min_cols(~3,      x)) </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;                Type of random forest: regression</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;                      Number of trees: 1000</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; No. of variables tried at each split: 3</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;           Mean of squared residuals: 0.00847</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;                     % Var explained: 72.5</span>
</span></span></code></pre></div><p>Look at the formula code that was printed out; one function uses the argument name <code>ntree</code> and the other uses <code>num.trees</code>. The parsnip models don&rsquo;t require you to know the specific names of the main arguments.</p>
<p>Now suppose that we want to modify the value of <code>mtry</code> based on the number of predictors in the data. Usually, a good default value is <code>floor(sqrt(num_predictors))</code> but a pure bagging model requires an <code>mtry</code> value equal to the total number of parameters. There may be cases where you may not know how many predictors are going to be present when the model will be fit (perhaps due to the generation of indicator variables or a variable filter) so this might be difficult to know exactly ahead of time when you write your code.</p>
<p>When the model it being fit by parsnip, <a href="https://parsnip.tidymodels.org/reference/descriptors.html"><em>data descriptors</em></a> are made available. These attempt to let you know what you will have available when the model is fit. When a model object is created (say using <code>rand_forest()</code>), the values of the arguments that you give it are <em>immediately evaluated</em> unless you delay them. To delay the evaluation of any argument, you can used <code>rlang::expr()</code> to make an expression.</p>
<p>Two relevant data descriptors for our example model are:</p>
<ul>
<li><code>.preds()</code>: the number of predictor <em>variables</em> in the data set that are associated with the predictors <strong>prior to dummy variable creation</strong>.</li>
<li><code>.cols()</code>: the number of predictor <em>columns</em> after dummy variables (or other encodings) are created.</li>
</ul>
<p>Since ranger won&rsquo;t create indicator values, <code>.preds()</code> would be appropriate for <code>mtry</code> for a bagging model.</p>
<p>For example, let&rsquo;s use an expression with the <code>.preds()</code> descriptor to fit a bagging model:</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#00f">rand_forest</span>(mode <span style="color:#666">=</span> <span style="color:#ba2121">&#34;regression&#34;</span>, mtry <span style="color:#666">=</span> <span style="color:#00f">.preds</span>(), trees <span style="color:#666">=</span> <span style="color:#666">1000</span>) <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">set_engine</span>(<span style="color:#ba2121">&#34;ranger&#34;</span>) <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">fit</span>(
</span></span><span style="display:flex;"><span>    <span style="color:#00f">log10</span>(Sale_Price) <span style="color:#666">~</span> Longitude <span style="color:#666">+</span> Latitude <span style="color:#666">+</span> Lot_Area <span style="color:#666">+</span> Neighborhood <span style="color:#666">+</span> Year_Sold,
</span></span><span style="display:flex;"><span>    data <span style="color:#666">=</span> ames_train
</span></span><span style="display:flex;"><span>  )
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; parsnip model object</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Ranger result</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Call:</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~.preds(),      x), num.trees = ~1000, num.threads = 1, verbose = FALSE,      seed = sample.int(10^5, 1)) </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Type:                             Regression </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Number of trees:                  1000 </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Sample size:                      2197 </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Number of independent variables:  5 </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Mtry:                             5 </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Target node size:                 5 </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Variable importance mode:         none </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Splitrule:                        variance </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; OOB prediction error (MSE):       0.00867 </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; R squared (OOB):                  0.718</span>
</span></span></code></pre></div><h2 id="regularized-regression">Regularized regression</h2>
<p>A linear model might work for this data set as well. We can use the <code>linear_reg()</code> parsnip model. There are two engines that can perform regularization/penalization, the glmnet and sparklyr packages. Let&rsquo;s use the former here. The glmnet package only implements a non-formula method, but parsnip will allow either one to be used.</p>
<p>When regularization is used, the predictors should first be centered and scaled before being passed to the model. The formula method won&rsquo;t do that automatically so we will need to do this ourselves. We&rsquo;ll use the <a href="https://recipes.tidymodels.org/">recipes</a> package for these steps.</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>norm_recipe <span style="color:#666">&lt;-</span> 
</span></span><span style="display:flex;"><span>  <span style="color:#00f">recipe</span>(
</span></span><span style="display:flex;"><span>    Sale_Price <span style="color:#666">~</span> Longitude <span style="color:#666">+</span> Latitude <span style="color:#666">+</span> Lot_Area <span style="color:#666">+</span> Neighborhood <span style="color:#666">+</span> Year_Sold, 
</span></span><span style="display:flex;"><span>    data <span style="color:#666">=</span> ames_train
</span></span><span style="display:flex;"><span>  ) <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">step_other</span>(Neighborhood) <span style="color:#666">%&gt;%</span> 
</span></span><span style="display:flex;"><span>  <span style="color:#00f">step_dummy</span>(<span style="color:#00f">all_nominal</span>()) <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">step_center</span>(<span style="color:#00f">all_predictors</span>()) <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">step_scale</span>(<span style="color:#00f">all_predictors</span>()) <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">step_log</span>(Sale_Price, base <span style="color:#666">=</span> <span style="color:#666">10</span>) <span style="color:#666">%&gt;%</span> 
</span></span><span style="display:flex;"><span>  <span style="color:#408080;font-style:italic"># estimate the means and standard deviations</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">prep</span>(training <span style="color:#666">=</span> ames_train, retain <span style="color:#666">=</span> <span style="color:#008000;font-weight:bold">TRUE</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Now let&#39;s fit the model using the processed version of the data</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>glmn_fit <span style="color:#666">&lt;-</span> 
</span></span><span style="display:flex;"><span>  <span style="color:#00f">linear_reg</span>(penalty <span style="color:#666">=</span> <span style="color:#666">0.001</span>, mixture <span style="color:#666">=</span> <span style="color:#666">0.5</span>) <span style="color:#666">%&gt;%</span> 
</span></span><span style="display:flex;"><span>  <span style="color:#00f">set_engine</span>(<span style="color:#ba2121">&#34;glmnet&#34;</span>) <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">fit</span>(Sale_Price <span style="color:#666">~</span> ., data <span style="color:#666">=</span> <span style="color:#00f">bake</span>(norm_recipe, new_data <span style="color:#666">=</span> <span style="color:#008000;font-weight:bold">NULL</span>))
</span></span><span style="display:flex;"><span>glmn_fit
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; parsnip model object</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; Call:  glmnet::glmnet(x = maybe_matrix(x), y = y, family = &#34;gaussian&#34;,      alpha = ~0.5) </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;    Df %Dev Lambda</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 1   0  0.0 0.1380</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 2   1  2.0 0.1260</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 3   1  3.7 0.1150</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 4   1  5.3 0.1050</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 5   2  7.1 0.0953</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 6   3  9.6 0.0869</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 7   4 12.6 0.0791</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 8   5 15.4 0.0721</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 9   5 17.9 0.0657</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 10  7 20.8 0.0599</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 11  7 23.5 0.0545</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 12  7 25.8 0.0497</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 13  8 28.2 0.0453</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 14  8 30.3 0.0413</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 15  8 32.1 0.0376</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 16  8 33.7 0.0343</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 17  8 35.0 0.0312</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 18  8 36.1 0.0284</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 19  8 37.0 0.0259</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 20  9 37.9 0.0236</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 21  9 38.6 0.0215</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 22  9 39.3 0.0196</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 23  9 39.8 0.0179</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 24  9 40.3 0.0163</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 25 10 40.7 0.0148</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 26 11 41.1 0.0135</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 27 11 41.4 0.0123</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 28 11 41.6 0.0112</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 29 11 41.9 0.0102</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 30 12 42.1 0.0093</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 31 12 42.3 0.0085</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 32 12 42.4 0.0077</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 33 12 42.6 0.0070</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 34 12 42.7 0.0064</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 35 12 42.8 0.0059</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 36 12 42.8 0.0053</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 37 12 42.9 0.0049</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 38 12 43.0 0.0044</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 39 12 43.0 0.0040</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 40 12 43.0 0.0037</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 41 12 43.1 0.0034</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 42 12 43.1 0.0031</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 43 12 43.1 0.0028</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 44 12 43.1 0.0025</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 45 12 43.1 0.0023</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 46 12 43.2 0.0021</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 47 12 43.2 0.0019</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 48 12 43.2 0.0018</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 49 12 43.2 0.0016</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 50 12 43.2 0.0014</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 51 12 43.2 0.0013</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 52 12 43.2 0.0012</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 53 12 43.2 0.0011</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 54 12 43.2 0.0010</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 55 12 43.2 0.0009</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 56 12 43.2 0.0008</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 57 12 43.2 0.0008</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 58 12 43.2 0.0007</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 59 12 43.2 0.0006</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 60 12 43.2 0.0006</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 61 12 43.2 0.0005</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 62 12 43.2 0.0005</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 63 12 43.2 0.0004</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 64 12 43.2 0.0004</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 65 12 43.2 0.0004</span>
</span></span></code></pre></div><p>If <code>penalty</code> were not specified, all of the <code>lambda</code> values would be computed.</p>
<p>To get the predictions for this specific value of <code>lambda</code> (aka <code>penalty</code>):</p>
<div class="highlight"><pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># First, get the processed version of the test set predictors:</span>
</span></span><span style="display:flex;"><span>test_normalized <span style="color:#666">&lt;-</span> <span style="color:#00f">bake</span>(norm_recipe, new_data <span style="color:#666">=</span> ames_test, <span style="color:#00f">all_predictors</span>())
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>test_results <span style="color:#666">&lt;-</span> 
</span></span><span style="display:flex;"><span>  test_results <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">rename</span>(`random forest` <span style="color:#666">=</span> .pred) <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00f">bind_cols</span>(
</span></span><span style="display:flex;"><span>    <span style="color:#00f">predict</span>(glmn_fit, new_data <span style="color:#666">=</span> test_normalized) <span style="color:#666">%&gt;%</span>
</span></span><span style="display:flex;"><span>      <span style="color:#00f">rename</span>(glmnet <span style="color:#666">=</span> .pred)
</span></span><span style="display:flex;"><span>  )
</span></span><span style="display:flex;"><span>test_results
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; # A tibble: 733 × 3</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;    Sale_Price `random forest` glmnet</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;         &lt;dbl&gt;           &lt;dbl&gt;  &lt;dbl&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  1       5.39            5.25   5.16</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  2       5.28            5.29   5.27</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  3       5.23            5.26   5.24</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  4       5.21            5.30   5.24</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  5       5.60            5.51   5.24</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  6       5.32            5.29   5.26</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  7       5.17            5.14   5.18</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  8       5.06            5.13   5.17</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;  9       4.98            5.01   5.18</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 10       5.11            5.14   5.19</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; # … with 723 more rows</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>test_results <span style="color:#666">%&gt;%</span> <span style="color:#00f">metrics</span>(truth <span style="color:#666">=</span> Sale_Price, estimate <span style="color:#666">=</span> glmnet) 
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; # A tibble: 3 × 3</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;   .metric .estimator .estimate</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt;   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 1 rmse    standard      0.142 </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 2 rsq     standard      0.391 </span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic">#&gt; 3 mae     standard      0.0979</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>test_results <span style="color:#666">%&gt;%</span> 
</span></span><span style="display:flex;"><span>  <span style="color:#00f">gather</span>(model, prediction, <span style="color:#666">-</span>Sale_Price) <span style="color:#666">%&gt;%</span> 
</span></span><span style="display:flex;"><span>  <span style="color:#00f">ggplot</span>(<span style="color:#00f">aes</span>(x <span style="color:#666">=</span> prediction, y <span style="color:#666">=</span> Sale_Price)) <span style="color:#666">+</span> 
</span></span><span style="display:flex;"><span>  <span style="color:#00f">geom_abline</span>(col <span style="color:#666">=</span> <span style="color:#ba2121">&#34;green&#34;</span>, lty <span style="color:#666">=</span> <span style="color:#666">2</span>) <span style="color:#666">+</span> 
</span></span><span style="display:flex;"><span>  <span style="color:#00f">geom_point</span>(alpha <span style="color:#666">=</span> <span style="color:#666">.4</span>) <span style="color:#666">+</span> 
</span></span><span style="display:flex;"><span>  <span style="color:#00f">facet_wrap</span>(<span style="color:#666">~</span>model) <span style="color:#666">+</span> 
</span></span><span style="display:flex;"><span>  <span style="color:#00f">coord_fixed</span>()
</span></span></code></pre></div><img src="figs/glmn-pred-1.svg" width="672" />
<p>This final plot compares the performance of the random forest and regularized regression models.</p>
<h2 id="session-information">Session information</h2>
<pre tabindex="0"><code>#&gt; ─ Session info ─────────────────────────────────────────────────────
#&gt;  setting  value
#&gt;  version  R version 4.1.2 (2021-11-01)
#&gt;  os       macOS Monterey 12.3
#&gt;  system   aarch64, darwin20
#&gt;  ui       X11
#&gt;  language (EN)
#&gt;  collate  en_GB.UTF-8
#&gt;  ctype    en_GB.UTF-8
#&gt;  tz       Europe/London
#&gt;  date     2022-04-11
#&gt;  pandoc   2.14.0.3 @ /Applications/RStudio.app/Contents/MacOS/pandoc/ (via rmarkdown)
#&gt; 
#&gt; ─ Packages ─────────────────────────────────────────────────────────
#&gt;  package      * version date (UTC) lib source
#&gt;  broom        * 0.7.12  2022-01-28 [1] CRAN (R 4.1.1)
#&gt;  dials        * 0.1.1   2022-04-06 [1] CRAN (R 4.1.2)
#&gt;  dplyr        * 1.0.8   2022-02-08 [1] CRAN (R 4.1.2)
#&gt;  ggplot2      * 3.3.5   2021-06-25 [1] CRAN (R 4.1.1)
#&gt;  glmnet       * 4.1-3   2021-11-02 [1] CRAN (R 4.1.2)
#&gt;  infer        * 1.0.0   2021-08-13 [1] CRAN (R 4.1.1)
#&gt;  parsnip      * 0.2.1   2022-03-17 [1] CRAN (R 4.1.1)
#&gt;  purrr        * 0.3.4   2020-04-17 [1] CRAN (R 4.1.0)
#&gt;  randomForest * 4.7-1   2022-02-03 [1] CRAN (R 4.1.2)
#&gt;  ranger       * 0.13.1  2021-07-14 [1] CRAN (R 4.1.2)
#&gt;  recipes      * 0.2.0   2022-02-18 [1] CRAN (R 4.1.1)
#&gt;  rlang          1.0.2   2022-03-04 [1] CRAN (R 4.1.1)
#&gt;  rsample      * 0.1.1   2021-11-08 [1] CRAN (R 4.1.2)
#&gt;  tibble       * 3.1.6   2021-11-07 [1] CRAN (R 4.1.1)
#&gt;  tidymodels   * 0.2.0   2022-03-19 [1] CRAN (R 4.1.1)
#&gt;  tune         * 0.2.0   2022-03-19 [1] CRAN (R 4.1.2)
#&gt;  workflows    * 0.2.6   2022-03-18 [1] CRAN (R 4.1.2)
#&gt;  yardstick    * 0.0.9   2021-11-22 [1] CRAN (R 4.1.1)
#&gt; 
#&gt;  [1] /Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/library
#&gt; 
#&gt; ────────────────────────────────────────────────────────────────────
</code></pre>
      </div>


      <div class="article-footer">
      
      <div style="float:left">
      
      </div>
      
      
      <div style="float:right">
      
      <div class='itemTitle' align="right" style='font-size:.8em; line-height:2em'>Next</div>
        <a href="/learn/models/parsnip-nnet/">Classification models using a neural network</a>
      
      </div>
     </div> 

      </div>

      <div class="column25">
        <div class="section hideOnMobile">
          <div class="sectionTitle">Contents</div>
          <nav id="TableOfContents">
  <ul>
    <li><a href="#introduction">Introduction</a></li>
    <li><a href="#the-ames-housing-data">The Ames housing data</a></li>
    <li><a href="#random-forest">Random forest</a></li>
    <li><a href="#regularized-regression">Regularized regression</a></li>
    <li><a href="#session-information">Session information</a></li>
  </ul>
</nav>
        </div>
      
        <div class="section">
          <div class="sectionTitle">Resources</div>
          




<div class="event">
  
  <div class="eventTitle">
    <a href="/find/"><i class="fas fa-search fa-xs"></i>&nbsp;&nbsp;Find</a>
  </div>
  <div class="eventDetails">Explore searchable tables of all tidymodels packages and functions.</div>
</div>






<div class="event">
  
  <div class="eventTitle">
    <a href="/books/"><i class="fas fa-book-open fa-xs"></i>&nbsp;&nbsp;Books</a>
  </div>
  <div class="eventDetails">Study up on statistics and modeling with our comprehensive books.</div>
</div>






<div class="event">
  
  <div class="eventTitle">
    <a href="https://www.tidyverse.org/tags/tidymodels/" target="_blank"><i class="fas fa-bullhorn fa-xs"></i>&nbsp;&nbsp;News</a>
  </div>
  <div class="eventDetails">Hear the latest about tidymodels packages at the <a href="https://www.tidyverse.org/tags/tidymodels/">tidyverse blog</a>.</div>
</div>



        </div>
      </div>
      


    </div>
  </div>  
</div> 


        <div id="rStudioFooter" class="band">
          <div class="bandContent">
            <div id="copyright">
              
              
              Proudly supported by <a class="rstudioLogo" href="https://www.rstudio.com/"></a>
              
            </div>
            <div id="logos">
              
              
            </div>
            
            <span class="float-right" aria-hidden="true">
              <a href="#" class="back-to-top">
                <span class="button_icon">
                  <i class="fas fa-chevron-up fa-2x"></i>
                </span>
              </a>
            </span>
            
          </div>
        </div>

      </div>  
    </div>  

    

    
<script src="/js/math-code.js"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true
  }
});
</script>
<script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-20375833-29', 'auto');
	
	ga('send', 'pageview');
}
</script>

  </body>
</html>

</body>
</html>
